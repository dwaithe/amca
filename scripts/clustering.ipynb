{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering of VGG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading/processing the images  \n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "import time\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from skimage import io\n",
    "\n",
    "from find_maxima import find_maxima\n",
    "import tifffile\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from convert_ROI_to_cell_volumes import *\n",
    "\n",
    "from scipy import ndimage\n",
    "# for loading/processing the images  \n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image\n",
    "         \n",
    "            \n",
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE and Kmeans prediction of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trains from image volumes (without time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpaths = ['/Users/dominicwaithe/Desktop/special/']\n",
    "\n",
    "#pca = pickle.load(open( \"/Users/dominicwaithe/Desktop/cell_images/pca.pickle\", \"rb\" ))\n",
    "#kmeans = pickle.load(open( \"/Users/dominicwaithe/Desktop/cell_images/kmeans.pickle\", \"rb\" ))\n",
    "channel = 1\n",
    "cell_data = []\n",
    "\n",
    "imgnum = 0\n",
    "xs = []\n",
    "store_cell_feats = []\n",
    "for path in evalpaths:\n",
    "    data,roi_array = collect_info(path,channel,'raw')\n",
    "    \n",
    "    for cell in range(0,data.__len__()):\n",
    "        \n",
    "        img_vol = data[cell]\n",
    "        cell_shape = img_vol.__len__()\n",
    "        raw_img = img_vol[cell_shape//2]\n",
    "        nimg = normalise_for_8bit(raw_img)\n",
    "        img = Image.fromarray(np.uint8(nimg))\n",
    "        img = img.resize((224, 224), Image.ANTIALIAS)\n",
    "        \n",
    "        img = np.array(img)\n",
    "        reshaped_img = np.zeros((1,224,224,3))\n",
    "        reshaped_img[0,:,:,0] = img\n",
    "        reshaped_img[0,:,:,1] = img\n",
    "        reshaped_img[0,:,:,2] = img\n",
    "        # prepare image for model\n",
    "        imgx = preprocess_input(reshaped_img)\n",
    "        # get the feature vector\n",
    "        features = model.predict(imgx, use_multiprocessing=True)\n",
    "        store_cell_feats.append(features)\n",
    "        \n",
    "\n",
    "feat = np.array(list(store_cell_feats))\n",
    "feat = feat.reshape(-1,4096)\n",
    "# reduce the amount of dimensions in the feature vector\n",
    "pca = PCA(n_components=10, random_state=22)\n",
    "pca.fit(feat)\n",
    "\n",
    "\n",
    "#_TSNE = TSNE(n_components=2)\n",
    "#x = _TSNE.fit_transform(feat)\n",
    "\n",
    "#x = pca.transform(feat)\n",
    "\n",
    "# cluster feature vectors\n",
    "kmeans = KMeans(n_clusters=4,n_jobs=-1, random_state=22)\n",
    "kmeans.fit(x)\n",
    "x = pca.transform(feat)\n",
    "xs.append(x)\n",
    "cell_data.append(kmeans.predict(x))\n",
    "copy_to_clipboard(cell_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def copy_to_clipboard(cell_data):\n",
    "    stg = \"\"\n",
    "    maxt = 0\n",
    "    for num in range(0,cell_data.__len__()):\n",
    "        if cell_data[num].__len__() > maxt:\n",
    "            maxt = cell_data[num].__len__()\n",
    "    for idx in range(0,maxt):\n",
    "        for num in range(0,cell_data.__len__()):\n",
    "            if idx < cell_data[num].__len__():\n",
    "                stg += str(cell_data[num][idx]) \n",
    "            stg+=\"\\t\"\n",
    "        stg+='\\n'\n",
    "    pyperclip.copy(stg)\n",
    "    spam = pyperclip.paste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xs[0]\n",
    "labels = cell_data[0]\n",
    "bint = labels==0\n",
    "plt.plot(x[bint,0],x[bint,1],'x')\n",
    "bint = labels==1\n",
    "plt.plot(x[bint,0],x[bint,1],'bo')\n",
    "bint = labels==2\n",
    "plt.plot(x[bint,0],x[bint,1],'ko')\n",
    "bint = labels==3\n",
    "plt.plot(x[bint,0],x[bint,1],'+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries data\n",
    "Train from timeseries. Pools all cellular images from dataset for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeseries\n",
    "#Train from timeseries. Pools all cellular images from dataset for clustering.\n",
    "\n",
    "train_paths = ['/Users/dominicwaithe/Desktop/focused_stkoutMD2join_0016/']\n",
    "channel = 0\n",
    "cell_data = []\n",
    "\n",
    "imgnum = 0\n",
    "xs = []\n",
    "cell_img = []\n",
    "train_array_feats = []\n",
    "\n",
    "\n",
    "for path in train_paths:\n",
    "    data, roi_array = collect_info(path,channel,'raw')\n",
    "    \n",
    "    for cell in range(0,data.__len__()):\n",
    "        \n",
    "        img_vol = data[cell]\n",
    "        cell_shape = img_vol.__len__()\n",
    "       \n",
    "        if cell_shape > 200:\n",
    "            reshaped_img = np.zeros((cell_shape,224,224,3))\n",
    "            for i, raw_img in enumerate(img_vol):\n",
    "                t1 = time.time()\n",
    "                nimg = normalise_for_8bit(raw_img)\n",
    "                img = Image.fromarray(np.uint8(nimg))\n",
    "                img = img.resize((224, 224), Image.NEAREST,reducing_gap=3)\n",
    "                img = np.array(img)\n",
    "                \n",
    "                \n",
    "                reshaped_img[i,:,:,0] = img\n",
    "                reshaped_img[i,:,:,1] = img\n",
    "                reshaped_img[i,:,:,2] = img\n",
    "                cell_img.append(img)\n",
    "                # prepare image for model\n",
    "            imgx = preprocess_input(reshaped_img)\n",
    "            t2 = time.time()\n",
    "            # get the feature vector\n",
    "            features = model.predict(imgx, use_multiprocessing=True)\n",
    "            train_array_feats.extend(features)\n",
    "            \n",
    "            t3 = time.time()\n",
    "            print('time',t2-t1,t3-t2)\n",
    "\n",
    "feat = np.array(list(train_array_feats))\n",
    "feat = feat.reshape(-1,4096)\n",
    "pca = PCA(n_components=10, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)\n",
    "xs.append(x)\n",
    "kmeans = KMeans(n_clusters=3,n_jobs=-1, random_state=22)\n",
    "kmeans.fit(x)\n",
    "\n",
    "pickle.dump(pca,open( \"pca_timeseries.pickle\", \"wb\" ))\n",
    "pickle.dump(kmeans,open( \"kmeans_timeseries.pickle\", \"wb\" ))\n",
    "\n",
    "cell_data.append(kmeans.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries data\n",
    "Evaluates timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeseries\n",
    "#Evaluate with \n",
    "eval_paths = ['/Users/dominicwaithe/Desktop/focused_stkoutMD2join_0012/']\n",
    "\n",
    "pca = pickle.load(open( \"pca_timeseries.pickle\", \"rb\" ))\n",
    "kmeans = pickle.load(open( \"kmeans_timeseries.pickle\", \"rb\" ))\n",
    "channel = 0\n",
    "cell_data = []\n",
    "\n",
    "imgnum = 0\n",
    "xs = []\n",
    "cell_img = []\n",
    "#flowers_sub.sort()\n",
    "for path in eval_paths:\n",
    "    data, roi_array = collect_info(path,channel,'raw')\n",
    "    \n",
    "    for cell in range(0,data.__len__()):\n",
    "        \n",
    "        store_cell_feats = []\n",
    "        img_vol = data[cell]\n",
    "        cell_shape = img_vol.__len__()\n",
    "        \n",
    "        if cell_shape > 200:\n",
    "            reshaped_img = np.zeros((cell_shape,224,224,3))\n",
    "            for i, raw_img in enumerate(img_vol):\n",
    "                t1 = time.time()\n",
    "                nimg = normalise_for_8bit(raw_img)\n",
    "                img = Image.fromarray(np.uint8(nimg))\n",
    "                img = img.resize((224, 224), Image.NEAREST,reducing_gap=3)\n",
    "                img = np.array(img)\n",
    "                \n",
    "                \n",
    "                reshaped_img[i,:,:,0] = img\n",
    "                reshaped_img[i,:,:,1] = img\n",
    "                reshaped_img[i,:,:,2] = img\n",
    "                cell_img.append(img)\n",
    "                # prepare image for model\n",
    "            imgx = preprocess_input(reshaped_img)\n",
    "            t2 = time.time()\n",
    "            # get the feature vector\n",
    "            features = model.predict(imgx, use_multiprocessing=True)\n",
    "            store_cell_feats.extend(features)\n",
    "            \n",
    "            t3 = time.time()\n",
    "            print('time',t2-t1,t3-t2)\n",
    "        if store_cell_feats.__len__()>0:\n",
    "            feat = np.array(list(store_cell_feats))\n",
    "            feat = feat.reshape(-1,4096)\n",
    "            x = pca.transform(feat)\n",
    "            xs.append(x)\n",
    "            cell_data.append(kmeans.predict(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualises clustering.\n",
    "Train from timeseries. Pools all cellular images from dataset for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "for dc in range(0,xs.__len__()):\n",
    "    i =0\n",
    "    dim0 = 0\n",
    "    dim1 = 1\n",
    "    #dc = 2\n",
    "   \n",
    "    \n",
    "    if xs[dc].__len__() >15:\n",
    "        #fig = plt.figure()\n",
    "        #plt.ylim(-30,30)\n",
    "        #plt.xlim(-60,60)\n",
    "        #ax  = Axes3D(fig)\n",
    "\n",
    "\n",
    "        for xy,clu in zip(xs[dc],cell_data[dc]):\n",
    "            b = [xy[dim0],xy[dim1]]\n",
    "           \n",
    "            if clu == 0:\n",
    "                \n",
    "                #ax.scatter(b[0], b[1], i,marker='o',color='c')\n",
    "                #.plot(b[0],i,'cx')\n",
    "                plt.plot(dc,i,'yx')\n",
    "                #plt.plot(b[0],b[1],'co',alpha=0.2)\n",
    "                pass\n",
    "            if clu == 1:\n",
    "                #ax.scatter(b[0], b[1], i,marker='o',color='b')\n",
    "                #plt.plot(b[0],i,'bo')\n",
    "                plt.plot(dc,i,'bo')\n",
    "                #plt.plot(b[0],b[1],'bo',alpha=0.2)\n",
    "                pass\n",
    "            if clu == 2:\n",
    "                #ax.scatter(b[0], b[1], i,marker='o',color='k')\n",
    "                #plt.plot(b[0],i,'ko')\n",
    "                plt.plot(dc,i,'ko')\n",
    "                #plt.plot(b[0],b[1],'ko',alpha=0.2)\n",
    "                pass\n",
    "            if clu == 3:\n",
    "                \n",
    "                #ax.scatter(b[0], b[1], i,marker='o',color='y')\n",
    "                #plt.plot(b[0],i,'yo')\n",
    "                plt.plot(dc,i,'yo')\n",
    "                \n",
    "                #plt.plot(b[0],b[1],'yo',alpha=0.2)\n",
    "                pass\n",
    "            #if i >0:\n",
    "                #rgb = np.array([np.random.random(),np.random.random(),np.random.random()])#\n",
    "                #rgb = (1-(float(i)/float(256)))\n",
    "                #ax.plot3D([c[0],b[0]], [c[1],b[1]], [i-1,i], color=rgb )# Data for three-dimensional scattered points\n",
    "\n",
    "                \n",
    "                #if np.sqrt((b[0]-c[0])**2+ (b[1]-c[1])**2) <20:\n",
    "                #plt.arrow(c[0],c[1],b[0]-c[0],b[1]-c[1],color=[rgb,rgb,rgb],width=0.1,alpha=1)\n",
    "            c = b\n",
    "            i +=1/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that lets you view a cluster (based on identifier)        \n",
    "def view_cluster(cell_data,cell_img,cluster):\n",
    "    plt.figure(figsize = (25,25));\n",
    "    # gets the list of filenames for a cluster\n",
    "    indices  = np.where(np.array(cell_data) == cluster)[0]\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    files = np.array(cell_img)[indices]\n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(files) > 100:\n",
    "        print(f\"Clipping cluster size from {len(files)} to 30\")\n",
    "        files = files[:99]\n",
    "    # plot each image in the cluster\n",
    "    for index, file in enumerate(files):\n",
    "        plt.subplot(10,10,index+1);\n",
    "        \n",
    "        img = np.array(file)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(cell_data[0],cell_img,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(cell_data[0],cell_img,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cluster(cell_data[0],cell_img,2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
