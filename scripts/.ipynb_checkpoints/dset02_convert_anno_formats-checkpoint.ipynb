{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of VOC xml annotation style to YOLOv2.0 list\n",
    "Functions and class definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 dataset neuroblastoma_phal_class/2018/\n",
      "index: 1 dataset neuroblastoma_phal_class/2018/\n",
      "index: 2 dataset neuroblastoma_phal_class/2018/\n",
      "index: 3 dataset neuroblastoma_phal_class/2018/\n",
      "index: 4 dataset neuroblastoma_phal_class/2018/\n",
      "index: 5 dataset neuroblastoma_phal_class/2018/\n",
      "index: 6 dataset neuroblastoma_phal_class/2018/\n",
      "index: 7 dataset neuroblastoma_phal_dapi_class/2018/\n",
      "index: 8 dataset erythroblast_dapi_class/2018/\n",
      "index: 9 dataset erythroblast_dapi_glycophorinA_class/2018/\n",
      "index: 10 dataset c127_dapi_class/2018/\n",
      "index: 11 dataset eukaryote_dapi_class/2018/\n",
      "index: 12 dataset fibroblast_nucleopore_class/2018/\n",
      "index: 13 dataset hek_peroxisome_class/2018/\n",
      "index: 14 dataset hek_peroxisome_all_class/2018/\n",
      "index: 15 dataset erythroid_dapi_all_class/2019/\n",
      "index: 16 dataset erythroid_dapi_class/2019/\n",
      "index: 17 dataset cos7_nucleopore_class/2019/\n",
      "index: 18 dataset cos7_nucleopore_scale_1p0_class/2019/\n",
      "index: 19 dataset cos7_nucleopore_scale_0p25_class/2019/\n",
      "index: 20 dataset cos7_nucleopore_scale_0p1_class/2019/\n",
      "index: 21 dataset c127_dapi_scale_1p0_class/2018/\n",
      "index: 22 dataset c127_dapi_scale_0p25_class/2018/\n",
      "index: 23 dataset c127_dapi_scale_0p1_class/2018/\n",
      "index: 24 dataset erythroid_dapi_all_scale_1p0_class/2019/\n",
      "index: 25 dataset erythroid_dapi_all_scale_0p25_class/2019/\n",
      "index: 26 dataset erythroid_dapi_all_scale_0p1_class/2019/\n",
      "index: 27 dataset cos7_nucleopore_scale_10x_class/2019/\n",
      "index: 28 dataset cos7_nucleopore_scale_40x_class/2019/\n",
      "index: 29 dataset cos7_nucleopore_scale_6p15_10x_class/2019/\n",
      "index: 30 dataset cos7_nucleopore_scale_1p5_40x_class/2019/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import convert_voc_to_other as cvto\n",
    "import numpy as np\n",
    "\n",
    "#Local absolute path to the folder containing the files.\n",
    "local_path = \"/Users/dominicwaithe/Documents/collaborators/WaitheD/micro_vision/cell_datasets/\"\n",
    "#For the files that require server location\n",
    "path_on_server = '../../cell_datasets/'\n",
    "#The save location of the models.\n",
    "models_path_on_server = \"/scratch/dwaithe/models/\" #This is for harrier.\n",
    "#Read the dataset specification file:\n",
    "path_to_spec = \"/Users/dominicwaithe/Documents/collaborators/WaitheD/micro_vision/amca/config/dataset_spec.txt\"\n",
    "indices, datasets, datasets_size, datasets_class = cvto.return_dataset_spec(path_to_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_n0.txt\n",
      "test_n19.txt\n",
      "written to directory: /Users/dominicwaithe/Documents/collaborators/WaitheD/micro_vision/cell_datasets/cos7_nucleopore_scale_6p15_10x_class/2019/ImageSets/Main/\n",
      "train_n0.txt\n",
      "test_n11.txt\n",
      "written to directory: /Users/dominicwaithe/Documents/collaborators/WaitheD/micro_vision/cell_datasets/cos7_nucleopore_scale_1p5_40x_class/2019/ImageSets/Main/\n"
     ]
    }
   ],
   "source": [
    "#Generates ImageSet lists for the PASCAL dataset.\n",
    "#This overwrites the existing, so be careful. \n",
    "#Seed mechanism seems to have changed since original.\n",
    "#Only run for new datasets.\n",
    "#for dataset,dataset_size in zip(datasets[29:31],datasets_size[29:31]):\n",
    "#    cvto.generate_random_list(dataset_size, local_path+dataset)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts the test and train files lists into YoloV2 and RetinaNet format.\n",
    " Updating the .name and .obj files For single and global classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_dapi_class/2018/\n",
      "erythroblast_dapi_class/2018/\n",
      "erythroblast_dapi_glycophorinA_class/2018/\n",
      "c127_dapi_class/2018/\n",
      "eukaryote_dapi_class/2018/\n",
      "fibroblast_nucleopore_class/2018/\n",
      "hek_peroxisome_class/2018/\n",
      "hek_peroxisome_all_class/2018/\n",
      "erythroid_dapi_all_class/2019/\n",
      "erythroid_dapi_class/2019/\n",
      "cos7_nucleopore_class/2019/\n",
      "cos7_nucleopore_scale_1p0_class/2019/\n",
      "cos7_nucleopore_scale_0p25_class/2019/\n",
      "cos7_nucleopore_scale_0p1_class/2019/\n",
      "c127_dapi_scale_1p0_class/2018/\n",
      "c127_dapi_scale_0p25_class/2018/\n",
      "c127_dapi_scale_0p1_class/2018/\n",
      "erythroid_dapi_all_scale_1p0_class/2019/\n",
      "erythroid_dapi_all_scale_0p25_class/2019/\n",
      "erythroid_dapi_all_scale_0p1_class/2019/\n",
      "cos7_nucleopore_scale_10x_class/2019/\n",
      "cos7_nucleopore_scale_40x_class/2019/\n",
      "cos7_nucleopore_scale_6p15_10x_class/2019/\n",
      "cos7_nucleopore_scale_1p5_40x_class/2019/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_class/2018/\n",
      "neuroblastoma_phal_dapi_class/2018/\n",
      "erythroblast_dapi_class/2018/\n",
      "erythroblast_dapi_glycophorinA_class/2018/\n",
      "c127_dapi_class/2018/\n",
      "eukaryote_dapi_class/2018/\n",
      "fibroblast_nucleopore_class/2018/\n",
      "hek_peroxisome_class/2018/\n",
      "hek_peroxisome_all_class/2018/\n",
      "erythroid_dapi_all_class/2019/\n",
      "erythroid_dapi_class/2019/\n",
      "cos7_nucleopore_class/2019/\n",
      "cos7_nucleopore_scale_1p0_class/2019/\n",
      "cos7_nucleopore_scale_0p25_class/2019/\n",
      "cos7_nucleopore_scale_0p1_class/2019/\n",
      "c127_dapi_scale_1p0_class/2018/\n",
      "c127_dapi_scale_0p25_class/2018/\n",
      "c127_dapi_scale_0p1_class/2018/\n",
      "erythroid_dapi_all_scale_1p0_class/2019/\n",
      "erythroid_dapi_all_scale_0p25_class/2019/\n",
      "erythroid_dapi_all_scale_0p1_class/2019/\n",
      "cos7_nucleopore_scale_10x_class/2019/\n",
      "cos7_nucleopore_scale_40x_class/2019/\n",
      "cos7_nucleopore_scale_6p15_10x_class/2019/\n",
      "cos7_nucleopore_scale_1p5_40x_class/2019/\n"
     ]
    }
   ],
   "source": [
    "#Generate the converted files.\n",
    "cvto.create_YOLO_single(datasets,datasets_size,datasets_class,local_path,path_on_server,models_path_on_server)\n",
    "cvto.create_retinaNet_single(datasets,datasets_size,local_path,models_path_on_server)\n",
    "\n",
    "#Read the mixed file specification file:\n",
    "path_to_mixed_file_spec = \"/Users/dominicwaithe/Documents/collaborators/WaitheD/micro_vision/amca/config/mixed_dataset_spec.txt\"\n",
    "indices, params = cvto.return_mixed_dataset_spec(path_to_mixed_file_spec)\n",
    "cvto.create_FasterRCNN_mixed_dataset(params, datasets,datasets_size,datasets_class,local_path,path_on_server,models_path_on_server)\n",
    "cvto.create_YOLO_mixed_hetero_class(params, datasets,datasets_size,datasets_class,local_path,path_on_server,models_path_on_server)\n",
    "cvto.create_retinaNet_global(params,datasets,datasets_size,local_path,models_path_on_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic tools    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This imports images and labels from YOLO and converts them into plot coordinates\n",
    "Just to test that my label files created for YOLO match those from YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pylab as plt\n",
    "\n",
    "path_in = '/Users/dwaithe/Documents/collaborators/WaitheD/micro_vision/Faster-RCNN-TensorFlow-Python3.5/data/fibroblast_nucleopore_class/2018/'\n",
    "f = open(path_in+'labels/010055.txt',\"r\")\n",
    "img = plt.imread(path_in+\"JPEGImages/010055.jpg\")\n",
    "\n",
    "path_in = '/Users/dwaithe/Documents/collaborators/WaitheD/micro_vision/Faster-RCNN-TensorFlow-Python3.5/data/neuroblastoma_phal_class/2018/'\n",
    "f = open(path_in+'labels/110082.txt',\"r\")\n",
    "img = plt.imread(path_in+\"JPEGImages/110082.jpg\")\n",
    "\n",
    "path_in = '/Users/dwaithe/Documents/collaborators/WaitheD/micro_vision/Faster-RCNN-TensorFlow-Python3.5/data/c127_dapi_class/2018/'\n",
    "f = open(path_in+'labels/108633.txt',\"r\")\n",
    "img = plt.imread(path_in+\"JPEGImages/108633.jpg\")\n",
    "height, width = img.shape\n",
    "print(height,width)\n",
    "\n",
    "lines =[]\n",
    "while 1:\n",
    "    line = f.readline()\n",
    "    print(line)\n",
    "    if not line:\n",
    "        break\n",
    "    lines.append(line)\n",
    "figure()\n",
    "imshow(img) \n",
    "for line in lines:\n",
    "    ele = line.split(\" \")\n",
    "    xmin = float(ele[1])*width\n",
    "    ymin = float(ele[2])*height\n",
    "    wid = float(ele[3])*width\n",
    "    hei = float(ele[4].split(\"\\r\")[0])*height\n",
    "    print(xmin,ymin,wid,hei)\n",
    "    \n",
    "    plta = [xmin-(wid//2),xmin-(wid//2),xmin+(wid//2),xmin+(wid//2),xmin-(wid//2)]\n",
    "    pltb = [ymin-(hei//2),ymin+(hei//2),ymin+(hei//2),ymin-(hei//2),ymin-(hei//2)]\n",
    "    \n",
    "    plot(plta,pltb,'-')\n",
    "    \n",
    " \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pylab as plt\n",
    "\n",
    "\n",
    "def return_lines(path):\n",
    "    f = open(path,\"r\")\n",
    "    lines =[]\n",
    "    while 1:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        lines.append(line)\n",
    "    f.close()\n",
    "    return lines\n",
    "def plot_frames(img, lines,cp):\n",
    "    height, width = img.shape\n",
    "    print(height,width)\n",
    "    for line in lines:\n",
    "        ele = line.split(\" \")\n",
    "        if ele[0] == img_id:\n",
    "            if float(ele[1]) > 0.25: #This is the YOLOv2 threshold for detection.\n",
    "                xmin = float(ele[2])#float(ele[1])*width\n",
    "                ymin =  float(ele[3]) #float(ele[2])*height\n",
    "                xmax =  float(ele[4])#float(ele[3])*width\n",
    "                ymax =  float(ele[5])#float(ele[4].split(\"\\r\")[0])*height\n",
    "\n",
    "                plta = [xmin,xmin,xmax,xmax,xmin]\n",
    "                pltb = [ymin,ymax,ymax,ymin,ymin]\n",
    "                plot(plta,pltb,cp)\n",
    "    return\n",
    "def plot_gt(img, lines,cp):\n",
    "    height, width = img.shape\n",
    "   \n",
    "    for line in lines:\n",
    "        ele = line.split(\" \")\n",
    "        \n",
    "        #if float(ele[1]) > 0.25: #This is the YOLOv2 threshold for detection.\n",
    "        xmin =float(ele[1])*width\n",
    "        ymin =float(ele[2])*height\n",
    "        wid = float(ele[3])*width\n",
    "        hei = float(ele[4].split(\"\\r\")[0])*height\n",
    "\n",
    "        #print(xmin,ymin,wid,hei)\n",
    "\n",
    "        plta = [xmin-(wid//2),xmin-(wid//2),xmin+(wid//2),xmin+(wid//2),xmin-(wid//2)]\n",
    "        pltb = [ymin-(hei//2),ymin+(hei//2),ymin+(hei//2),ymin-(hei//2),ymin-(hei//2)]\n",
    "        plot(plta,pltb,cp)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dateset_path = '../../cell_datasets/erythroid_dapi_all_class/2019'\n",
    "\n",
    "path_in = '/JPEGImages/'\n",
    "img_id = '164514'\n",
    "figure(figsize(14,14))\n",
    "img = plt.imread(dateset_path+path_in+img_id+\".jpg\")\n",
    "path_in = '/Users/dominicwaithe/Desktop/'\n",
    "\n",
    "#ALL predictions\n",
    "lines = return_lines(path_in+'comp4_det_test_dn_n50_cell - erythroid dapi all_10000.txt')\n",
    "plot_frames(img, lines,'r-')\n",
    "\n",
    "\n",
    "\n",
    "#ALL ground-truth\n",
    "dateset_path = '../../cell_datasets/erythroid_dapi_all_class/2019'\n",
    "path_in2 = dateset_path+'/labels/'\n",
    "lines = return_lines(path_in2+img_id+'.txt')\n",
    "plot_gt(img, lines,'w-')\n",
    "\n",
    "imshow(img.astype(np.uint8),cmap='gray')\n",
    "\n",
    "figure()\n",
    "#non-blebbly predictions\n",
    "lines = return_lines(path_in+'comp4_det_test_dn_n50_cell - erythroid dapi_10000.txt')\n",
    "plot_frames(img, lines,'r--')\n",
    "\n",
    "\n",
    "#non-blebbly ground-truth\n",
    "dateset_path = '../../cell_datasets/erythroid_dapi_class/2019'\n",
    "path_in2 = dateset_path+'/labels/'\n",
    "lines = return_lines(path_in2+img_id+'.txt')\n",
    "plot_gt(img, lines,'w--')\n",
    "imshow(img.astype(np.uint8),cmap='gray')\n",
    " \n",
    "\n",
    "\n",
    "plt.savefig('/Users/dominicwaithe/Desktop/'+img_id+'.eps', dpi=300, facecolor='w', edgecolor='w',  pad_inches=0.0, frameon=False, metadata=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many cells there are in an image\n",
    "Calculates how many cells there are in an image on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    cell_num = []\n",
    "    for file_nm in os.listdir(local_path+dataset+'Labels/'):\n",
    "\n",
    "        f = open(local_path+dataset+'Labels/'+file_nm)\n",
    "        lines = f.readlines()\n",
    "        #print('file_nm',file_nm,'num of lines',lines.__len__())\n",
    "        cell_num.append(lines.__len__())\n",
    "        f.close()\n",
    "    print( np.average(cell_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validates the VOC label format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    count_x_zero = 0\n",
    "    count_y_zero = 0\n",
    "    count_x_ones = 0\n",
    "    count_y_ones = 0\n",
    "    \n",
    "    count_wid = 0\n",
    "    count_hei = 0\n",
    "    count_wid_mone = 0\n",
    "    count_hei_mone = 0\n",
    "    count_wid_great = 0\n",
    "    count_hei_great = 0\n",
    "    \n",
    "    \n",
    "    count_files = 0\n",
    "    count_regions =0\n",
    "    for file_nm in os.listdir(path+dataset+'Annotations/'):\n",
    "        if file_nm.endswith(\".xml\"): \n",
    "            count_files +=1\n",
    "            data =  open(path+dataset+'Annotations/'+file_nm,\"r\")\n",
    "            out_str = \"\"\n",
    "            while 1:\n",
    "                line = data.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                #print line\n",
    "                if line.find(\"<name>\") >-1:\n",
    "                    im_class =  line.split(\"<name>\")[1].split(\"</name>\")[0]\n",
    "                if line.find(\"<width>\") >-1:\n",
    "                    im_width =  float(line.split(\"<width>\")[1].split(\"</width>\")[0])\n",
    "                if line.find(\"height\") >-1:\n",
    "                    im_height =  float(line.split(\"<height>\")[1].split(\"</height>\")[0])\n",
    "                if line.find(\"<bndbox>\") > -1:\n",
    "                    count_regions +=1\n",
    "                    xmin_str = data.readline()\n",
    "                    xmin = float(xmin_str.split(\"<xmin>\")[1].split(\"</xmin>\")[0])\n",
    "                    ymin_str = data.readline()\n",
    "                    ymin = float(ymin_str.split(\"<ymin>\")[1].split(\"</ymin>\")[0])\n",
    "                    xmax_str = data.readline()\n",
    "                    xmax = float(xmax_str.split(\"<xmax>\")[1].split(\"</xmax>\")[0])\n",
    "                    ymax_str = data.readline()\n",
    "                    ymax = float(ymax_str.split(\"<ymax>\")[1].split(\"</ymax>\")[0])\n",
    "                    #print(xmin,xmax,ymin,ymax)\n",
    "                    if xmin == 0:\n",
    "                        count_x_zero +=1\n",
    "                    if ymin == 0:\n",
    "                        count_y_zero +=1\n",
    "                    if xmin == 1:\n",
    "                        count_x_ones +=1\n",
    "                    if ymin == 1:\n",
    "                        count_y_ones +=1\n",
    "                    if xmax == im_width:\n",
    "                        count_wid +=1\n",
    "                    if ymax == im_height:\n",
    "                        count_hei +=1\n",
    "                    if xmax == im_width-1:\n",
    "                        count_wid_mone +=1\n",
    "                    if ymax == im_height-1:\n",
    "                        count_hei_mone +=1\n",
    "                    if xmax > im_width:\n",
    "                        count_wid_great +=1\n",
    "                    if ymax >im_height:\n",
    "                        count_hei_great +=1\n",
    "            data.close()\n",
    "    out = [count_files,count_regions,count_x_zero,count_y_zero,count_x_ones, count_y_ones,count_wid,count_hei]\n",
    "    out.extend([count_wid_mone,count_hei_mone,count_wid_great,count_hei_great])\n",
    "    print(dataset.split(\"/\")[0],out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 500\n",
    "seed = 500 & 0xFFFFFFFF\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "indices_to_use = np.random.choice(np.arange(0,55), size=100, replace=False)\n",
    "print(np.sort(indices_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "comparison = [108633,108634,108639,108640,108641,108642,108643,108645,108646,108649,108650,108651,108653,108655, 108659,108660, 108661,108663,108666,108670,108672,108673,108674,108677,108679,108687,108689,108693,108694,108696]\n",
    "\n",
    "\n",
    "def generate_random_list(number_to_include, directory,seed):\n",
    "    store_lines = []\n",
    "    for file in os.listdir(directory+\"/Annotations\"):\n",
    "        if file.endswith(\".xml\"):\n",
    "            #print(file[:-4])\n",
    "            store_lines.append(str(file[:-4]))\n",
    "\n",
    "\n",
    "    store_lines = np.sort(np.array(store_lines))\n",
    "    #print(store_lines)\n",
    "    #with open(out_filename) as f:\n",
    "    #\t\tfor line in f:\n",
    "\n",
    "    #print(store_lines.__len__())\n",
    "    np.random.seed(seed=seed)\n",
    "    #fraction = 0.5\n",
    "    #number_to_include = np.ceil(float(fraction)*float(store_lines.__len__()))\n",
    "\n",
    "    indices_to_use = np.random.choice(np.arange(0,store_lines.__len__()), size=store_lines.__len__(), replace=False)\n",
    "    split  = store_lines.__len__()//2\n",
    "    training_list = np.sort(indices_to_use[:split]).astype(np.int32)\n",
    "    test_list = np.sort(indices_to_use[split:]).astype(np.int)\n",
    "    #print('number_to_include',number_to_include)\n",
    "    #outF = open(\"train_n\"+str(int(number_to_include))+\".txt\", \"w\")\n",
    "    #store_lines = np.array(store_lines)\n",
    "    #print('num',store_lines[training_list[:int(number_to_include)]])\n",
    "    #print('num',test_list)\n",
    "    textList = list(map(lambda x: x, store_lines[training_list[:int(number_to_include)]]))\n",
    "    #print(textList)\n",
    "    #outF.writelines(\"%s\\n\" % l for l in textList)\n",
    "    #outF.close()\n",
    "\n",
    "    #outF = open(\"test_n\"+str(int(number_to_include))+\".txt\", \"w\")\n",
    "    textList = list(map(lambda x: x, store_lines[test_list[:int(number_to_include)]]))\n",
    "    #print(textList)\n",
    "    #outF.writelines(\"%s\\n\" % l for l in textList)\n",
    "    #outF.close()\n",
    "    diff = []\n",
    "    for txt, val in zip(textList, comparison):\n",
    "        diff.append(int(txt)!=int(val))\n",
    "    \n",
    "    \n",
    "    return diff\n",
    "\n",
    "\n",
    "\n",
    "directory = \"/Users/dwaithe/Documents/collaborators/WaitheD/micro_vision/cell_datasets/c127_dapi_class/2018/\"\n",
    "out_arry = []\n",
    "for seed in range(0,100000):\n",
    "    out_arry.append(np.sum(generate_random_list(int(30), directory,seed)))\n",
    "    print(seed,out_arry[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot(out_arry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_arry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
