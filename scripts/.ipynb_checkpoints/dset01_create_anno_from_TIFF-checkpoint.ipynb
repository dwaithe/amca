{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate XML annotation files and JPEGImages from TIFF files.\n",
    "\n",
    "* This notebook assumes that datasets have been stored locally on this machine and bounding regions annotated within Fiji/ImageJ.\n",
    "* If this is not the case, then you either want to maybe use the OMERO version of this script:\n",
    "dset01_create_anno_from_OMERO.ipynb  (This other notebook allows you to import ROI from tiff files directly).  \n",
    "* Creating a dataset forms the foundation of training material used to train one of many object detection algorithms.  \n",
    "* N.B. Once Finished here it is also important to add the information about this dataset to the config/dataset_spec.txt file.  \n",
    "* N.B. The next step after this is to run is to run the notebook dset02_create_anno_formats. This next notebook is used  create the  \n",
    "configuration files associated with the dataset and also allows you to group datasets together for larger training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import ijroi\n",
    "from ijroi.ij_roi import Roi\n",
    "from ijroi.ijpython_decoder import decode_ij_roi\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import convert_voc_to_other as cvto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Folder structure for new dataset\n",
    "First we need to create a folder structure on the file-system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the folder structure.\n",
    "dataset_home_dir = \"/Users/dominicwaithe/Documents/collaborators/WaitheD/micro_vision/cell_datasets/\"\n",
    "dataset_name = \"cos7_nucleopore_scale_40x_class\" #e.g. erythroblast_dapi_glycophorinA_FOXO3_class\n",
    "year_acquisition = \"2019\"\n",
    "class_name = \"cell - cos7 nucleopore\" #Classes to have in this dataset.\n",
    "###########\n",
    "## The above has to be added to config/dataset_spec.txt file.\n",
    "###########\n",
    "\n",
    "xml_path = dataset_home_dir+dataset_name+'/'+year_acquisition+'/Annotations'\n",
    "jpg_path = dataset_home_dir+dataset_name+'/'+year_acquisition+'/JPEGImages'\n",
    "# checking whether folder/directory exists\n",
    "if not os.path.exists(dataset_home_dir+dataset_name):\n",
    "    os.mkdir(dataset_home_dir+dataset_name)\n",
    "if not os.path.exists(dataset_home_dir+dataset_name+'/'+year_acquisition+'/'):\n",
    "    os.mkdir(dataset_home_dir+dataset_name+'/'+year_acquisition+'/')\n",
    "for dirm in [xml_path,jpg_path]:\n",
    "    if not os.path.exists(dirm):\n",
    "        os.mkdir(dirm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify folder containing the tiff files.\n",
    "and collect those files with ij_metadata (rather than OME metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['0001.tif', '0002.tif', '0003.tif', '0004.tif', '0005.tif', '0006.tif', '0007.tif', '0008.tif', '0009.tif', '0010.tif', '0011.tif']\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n",
      "I think this is an IJ tiff.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tifffile import TiffFile\n",
    "\n",
    "\n",
    "dir_to_read = \"/Users/dominicwaithe/Documents/collaborators/WaitheD/micro_vision/acquisitions/20200413_40x/\"\n",
    "myimages = [] #list of image filenames\n",
    "dirFiles = os.listdir(dir_to_read) #list of directory files\n",
    "dirFiles.sort() #good initial sort but doesnt sort numerically very well\n",
    "sorted(dirFiles) #sort numerically in ascending order\n",
    "\n",
    "for file in dirFiles: #filter out all non jpgs\n",
    "    if '.tiff' in file[-5:] or '.tif' in file[-4:]:\n",
    "        myimages.append(file)\n",
    "print (len(myimages))\n",
    "print (myimages)\n",
    "ij_tiff =[]\n",
    "ome_tiff = []\n",
    "for tiff in myimages:\n",
    "    img_to_open = dir_to_read+tiff\n",
    "    tf_img = TiffFile(img_to_open)\n",
    "    \n",
    "    if tf_img.ome_metadata !=None:\n",
    "        print('I think this is an OME tiff.')\n",
    "        ome_tiff.append(tiff)\n",
    "    elif tf_img.imagej_metadata !=None:\n",
    "        print('I think this is an IJ tiff.')\n",
    "        ij_tiff.append(tiff)\n",
    "        \n",
    "    tf_img.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate XML annotation files and JPEGImages from ImageJ Tifffiles.\n",
    "This cell takes a folder of ImageJ tiff images and annotations located on local computer.\n",
    "This script assumes that images have been annotated in fiji/ImageJ and the cell class has been used to label the ROI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input name: 0001.tif output name: 001300.jpg\n",
      "input name: 0002.tif output name: 001301.jpg\n",
      "input name: 0003.tif output name: 001302.jpg\n",
      "input name: 0004.tif output name: 001303.jpg\n",
      "input name: 0005.tif output name: 001304.jpg\n",
      "input name: 0006.tif output name: 001305.jpg\n",
      "input name: 0007.tif output name: 001306.jpg\n",
      "input name: 0008.tif output name: 001307.jpg\n",
      "input name: 0009.tif output name: 001308.jpg\n",
      "input name: 0010.tif output name: 001309.jpg\n",
      "input name: 0011.tif output name: 001310.jpg\n"
     ]
    }
   ],
   "source": [
    "#If you want to name your output images with a sequence (recommended), then set rename_with_seq=True\n",
    "rename_with_seq = True\n",
    "start_index = 1300 #Choose a sensible unique start.\n",
    "#If rename_with_seq = False, then the input name will be reused, with .jpg ending.\n",
    "annotator_name = \"Waithe\" \n",
    "override = True \n",
    "scale_factor = 1\n",
    "\n",
    "\n",
    "ct = 0\n",
    "for tiff in ij_tiff:\n",
    "    if rename_with_seq:\n",
    "        output_name = str(start_index+ct).zfill(6)\n",
    "    else:\n",
    "        output_name = tiff.split('.')[:-1][0]\n",
    "    \n",
    "    print('input name:',tiff,'output name: '+str(output_name)+'.jpg')\n",
    "    tfile = TiffFile(dir_to_read+tiff)\n",
    "    img_shape = tfile.asarray().shape\n",
    "\n",
    "    overlay_arr = []\n",
    "    if 'Overlays' in tfile.imagej_metadata:\n",
    "        overlays = tfile.imagej_metadata['Overlays']\n",
    "        if overlays.__class__.__name__ == 'list':\n",
    "            #Multiple overlays and so iterate.\n",
    "            for overlay in overlays:\n",
    "\n",
    "                overlay_arr.append(decode_ij_roi(overlay,img_shape))\n",
    "        else:\n",
    "            #One overlay.\n",
    "                overlay_arr.append(decode_ij_roi(overlays,img_shape))\n",
    "    else:\n",
    "        print('no Overlays present in file.')\n",
    "    \n",
    "    roi_list = []\n",
    "    for i in range(0,overlay_arr.__len__()):\n",
    "        if overlay_arr[i]:\n",
    "            roi_class_name = str(overlay_arr[i].name).replace(\"\\x00\", \"\")\n",
    "            x = overlay_arr[i].x\n",
    "            y = overlay_arr[i].y\n",
    "            width = overlay_arr[i].width\n",
    "            height = overlay_arr[i].height\n",
    "            roi_list.append([x, y, width, height, roi_class_name])\n",
    "            \n",
    "    \n",
    "    raw_img = tfile.asarray()\n",
    "    assert raw_img.shape.__len__() == 2, \"image should only have 2-dimensions.\"\n",
    "    sorted_img = np.sort(raw_img.flatten())\n",
    "    sat_fac = 0.3 #Matches Fiji/ImageJ saturation factor of 0.3%\n",
    "    img_min = int(np.ceil(sorted_img.shape[0]*((sat_fac/2.)/100.)))\n",
    "    img_max = int(np.floor(sorted_img.shape[0]*((100.-(sat_fac/2.))/100.)))\n",
    "\n",
    "    lower_bound = sorted_img[img_min]\n",
    "    upper_bound = sorted_img[img_max]\n",
    "\n",
    "    #This is very similar to the ImageJ/Fiji methodoloy when saving JPEGs but isn't exactly the same.\n",
    "    lut = np.concatenate([\n",
    "            np.zeros(lower_bound, dtype=np.uint16),\n",
    "            np.linspace(0, 255, upper_bound - lower_bound).astype(np.uint16),\n",
    "            np.ones(2**16 - upper_bound, dtype=np.uint16) * 255\n",
    "        ])\n",
    "\n",
    "    bit_img = lut[raw_img].astype(np.uint8)\n",
    "    corr_img = ndimage.interpolation.zoom(bit_img,scale_factor)\n",
    "\n",
    "    out_img = np.zeros((corr_img.shape[0],corr_img.shape[1],3))\n",
    "    out_img[:,:,0] = corr_img\n",
    "    out_img[:,:,1] = corr_img\n",
    "    out_img[:,:,2] = corr_img\n",
    "\n",
    "    #assert raw_img.shape[0] == 1024, \"input image is unexpected size\"\n",
    "    #assert out_img.shape[0] == 512, \"output image is unexpected size\"\n",
    "    \n",
    "    out_img = out_img.astype(np.uint8)\n",
    "    jpg_file = str(output_name)+\".jpg\"\n",
    "    #Save the JPEG image out to the folder\n",
    "    plt.imsave(jpg_path+'/'+jpg_file, out_img)\n",
    "    #Save the XML annotation out.\n",
    "    cvto.write_xml(xml_path, roi_list, output_name, dataset_name, class_name,override, year_acquisition, out_img.shape[1], out_img.shape[0], scale_factor)\n",
    "    ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
