{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate XML annotation files and JPEGImages from OMERO.\n",
    "\n",
    "* This notebook assumes that datasets have been collected and bounding regions annotated within OMERO.\n",
    "* If this is not the case, then you either want to do this by logging into OMERO Webclient.  \n",
    "Alternatively if you want to create dataset directly from TIFF files please use the notebook:  \n",
    "dset01_create_anno_from_TIFF.ipynb  (This other notebook allows you to import ROI from tiff files directly).  \n",
    "* Creating a dataset forms the foundation of training material used to train one of many object detection algorithms.  \n",
    "* N.B. Once Finished here it is also important to add the information about this dataset to the config/dataset_spec.txt file.  \n",
    "* N.B. The next step after this is to run is to run the notebook dset02_create_anno_formats. This next notebook is used  create the  \n",
    "configuration files associated with the dataset and also allows you to group datasets together for larger training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install omero-py\n",
    "from omero.gateway import BlitzGateway\n",
    "import omero\n",
    "import getpass\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import convert_voc_to_other as cvto\n",
    "import omero_interaction as om_i "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Folder structure for new dataset\n",
    "First we need to create a folder structure on the file-system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the folder structure.\n",
    "dataset_home_dir = \"/Users/dominicwaithe/Documents/collaborators/WaitheD/micro_vision/cell_datasets/\"\n",
    "dataset_name = \"erythroid_dapi_all_scale_0p25_class\" #e.g. erythroblast_dapi_glycophorinA_FOXO3_class\n",
    "year_acquisition = \"2019\"\n",
    "class_name = \"cell - erythroid dapi all\" #Classes to have in this dataset.\n",
    "###########\n",
    "## The above has to be added to config/dataset_spec.txt file.\n",
    "###########\n",
    "\n",
    "xml_path = dataset_home_dir+dataset_name+'/'+year_acquisition+'/Annotations'\n",
    "jpg_path = dataset_home_dir+dataset_name+'/'+year_acquisition+'/JPEGImages'\n",
    "# checking whether folder/directory exists\n",
    "if not os.path.exists(dataset_home_dir+dataset_name):\n",
    "    os.mkdir(dataset_home_dir+dataset_name)\n",
    "if not os.path.exists(dataset_home_dir+dataset_name+'/'+year_acquisition+'/'):\n",
    "    os.mkdir(dataset_home_dir+dataset_name+'/'+year_acquisition+'/')\n",
    "for dirm in [xml_path,jpg_path]:\n",
    "    if not os.path.exists(dirm):\n",
    "        os.mkdir(dirm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to OMERO\n",
    "Requires an OMERO instance, either locally or on a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your password ·················\n"
     ]
    }
   ],
   "source": [
    "PASSWORD = getpass.getpass('Enter your password')\n",
    "\n",
    "USERNAME = \"dwaithe\"\n",
    "HOST = \"cbomero.imm.ox.ac.uk\"\n",
    "PORT = 4064\n",
    "\n",
    "conn = BlitzGateway(USERNAME, PASSWORD, host=HOST, port=PORT)\n",
    "connected = conn.connect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate XML annotation files and JPEGImages from OMERO.\n",
    "This cell takes a particular OMERO dataset id and downloads the images and annotations located on OMERO server.  \n",
    "This script assumes that images have been annotated in OMERO and the cell class has been used to label the ROI.\n",
    "You can find the OMERO Id by looking at the dataset in either the OMERO Insight client or Webclient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMERO_dataset_num = 4379\n",
    "\n",
    "out_list = om_i.rtn_img_ids_from_dataset(OMERO_dataset_num,conn)\n",
    "\n",
    "annotator_name = \"Waithe\" #If you should have a different annnotator, this is where to change it.\n",
    "scale_factor = 0.25 #The networks take images close to 512, this scale-factor takes it near to this size.\n",
    "override = True #True means the classes in the OMERO will be ignored (so defined above) rather than taken from OMERO.\n",
    "#Loop which creates JPEGImage files and also XML annotations for training objection networks.\n",
    "\n",
    "for imageId in out_list:\n",
    "    raw_img = om_i.rtn_raw_image(imageId,conn).astype(np.uint16)\n",
    "    roi_list = om_i.rtn_roi(imageId,conn)\n",
    "    \n",
    "    #Here we stretch the pixel information across the available intensity range.\n",
    "    #This is very similar to the ImageJ/Fiji function.\n",
    "    sorted_img = np.sort(raw_img.flatten())\n",
    "    sat_fac = 0.3 #Matches Fiji/ImageJ saturation factor of 0.3%\n",
    "    img_min = int(np.ceil(sorted_img.shape[0]*((sat_fac/2.)/100.)))\n",
    "    img_max = int(np.floor(sorted_img.shape[0]*((100.-(sat_fac/2.))/100.)))\n",
    "\n",
    "    lower_bound = sorted_img[img_min]\n",
    "    upper_bound = sorted_img[img_max]\n",
    "\n",
    "    #This is very similar to the ImageJ/Fiji methodoloy when saving JPEGs but isn't exactly the same.\n",
    "    lut = np.concatenate([\n",
    "            np.zeros(lower_bound, dtype=np.uint16),\n",
    "            np.linspace(0, 255, upper_bound - lower_bound).astype(np.uint16),\n",
    "            np.ones(2**16 - upper_bound, dtype=np.uint16) * 255\n",
    "        ])\n",
    "\n",
    "\n",
    "    bit_img = lut[raw_img].astype(np.uint8)\n",
    "    corr_img = ndimage.interpolation.zoom(bit_img,scale_factor)\n",
    "\n",
    "    out_img = np.zeros((corr_img.shape[0],corr_img.shape[1],3))\n",
    "    out_img[:,:,0] = corr_img\n",
    "    out_img[:,:,1] = corr_img\n",
    "    out_img[:,:,2] = corr_img\n",
    "\n",
    "    #assert raw_img.shape[0] == 1024, \"input image is unexpected size\"\n",
    "    #assert out_img.shape[0] == 512, \"output image is unexpected size\"\n",
    "    file = out_list[0]\n",
    "    out_img = out_img.astype(np.uint8)\n",
    "    jpg_file = str(imageId)+\".jpg\"\n",
    "    #Save the JPEG image out to the folder\n",
    "    plt.imsave(jpg_path+'/'+jpg_file, out_img)\n",
    "    #Save the XML annotation out.\n",
    "    cvto.write_xml(xml_path, roi_list, imageId, dataset_name, class_name,override, year_acquisition, out_img.shape[1], out_img.shape[0], scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
